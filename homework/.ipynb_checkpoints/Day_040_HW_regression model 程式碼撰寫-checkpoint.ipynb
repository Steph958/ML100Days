{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "使用 Sklearn 中的 Lasso, Ridge 模型，來訓練各種資料集，務必了解送進去模型訓練的**資料型態**為何，也請了解模型中各項參數的意義。\n",
    "\n",
    "機器學習的模型非常多種，但要訓練的資料多半有固定的格式，確保你了解訓練資料的格式為何，這樣在應用新模型時，就能夠最快的上手開始訓練！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習時間\n",
    "試著使用 sklearn datasets 的其他資料集 (boston, ...)，來訓練自己的線性迴歸模型，並加上適當的正則化來觀察訓練情形。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用簡單線性模型做看看:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料集\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred1 = regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.15966452e-01  4.71249231e-02  8.25980146e-03  3.23404531e+00\n",
      " -1.66865890e+01  3.88410651e+00 -1.08974442e-02 -1.54129540e+00\n",
      "  2.93208309e-01 -1.34059383e-02 -9.06296429e-01  8.80823439e-03\n",
      " -4.57723846e-01]\n"
     ]
    }
   ],
   "source": [
    "print(regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 25.42\n"
     ]
    }
   ],
   "source": [
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "這是一個baseline，看看Redge和Lasso表現如何?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用Lasso做看看:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料集\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=4)\n",
    "\n",
    "# 建立一個Lasso線性回歸模型\n",
    "lasso = linear_model.Lasso(alpha=1.0)\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "lasso.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred2 = lasso.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06494981,  0.04581458, -0.        ,  0.        , -0.        ,\n",
       "        1.18140024,  0.01109101, -0.73695809,  0.23350042, -0.01551065,\n",
       "       -0.69270805,  0.00763157, -0.6927848 ])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 28.95\n"
     ]
    }
   ],
   "source": [
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4281.822264289709, tolerance: 3.3131348787128707\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "# 讀取資料集\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "seq = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "lasso_mse = []\n",
    "\n",
    "for alpha in seq:\n",
    "    lasso_test = linear_model.Lasso(alpha = alpha)\n",
    "    lasso_test.fit(x_train, y_train)\n",
    "    y_pred3 = lasso_test.predict(x_test)\n",
    "    lasso_mse.append( mean_squared_error(y_test, y_pred3))\n",
    "    \n",
    "    #print(\"Mean squared error: %.2f\"\n",
    "    #  % mean_squared_error(y_test, y_pred3))\n",
    "    \n",
    "    #print(\"Using alpha:%.2f\"\n",
    "    #  %alpha)\n",
    "    #print(\"============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "許多係數都變成 0，Lasso Regression 的確可以做特徵選取，但是MSE變得比之前要大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用Ridege做看看:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料集\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "ridge = linear_model.Ridge(alpha=1.0)\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "ridge.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred4 = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.12499445e-01  4.79562332e-02 -2.40438147e-02  2.96199458e+00\n",
      " -9.33966118e+00  3.93079015e+00 -1.73821202e-02 -1.43347691e+00\n",
      "  2.75239392e-01 -1.38920708e-02 -8.31116943e-01  9.15637729e-03\n",
      " -4.66460539e-01]\n"
     ]
    }
   ],
   "source": [
    "print(ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 25.74\n"
     ]
    }
   ],
   "source": [
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料集\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "seq = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "ridge_mse = []\n",
    "\n",
    "for alpha in seq:\n",
    "    Ridge_test = linear_model.Ridge(alpha=alpha)\n",
    "    Ridge_test.fit(x_train, y_train)\n",
    "    y_pred5 = Ridge_test.predict(x_test)\n",
    "    ridge_mse.append(mean_squared_error(y_test, y_pred5))\n",
    "    \n",
    "    #print(\"Mean squared error: %.2f\"\n",
    "     # % mean_squared_error(y_test, y_pred5))\n",
    "    \n",
    "    #print(\"Using alpha:%.2f\"\n",
    "     # %alpha)\n",
    "    #print(\"============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "看看Ridge 的參數，明顯比起 Linear Regression的參數都小了許多，然而MSE一樣比原來的要大。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "LASSO 與 Ridge 的結果並沒有比原本的線性回歸來得好，因為目標函數被加上了正規化函數，讓模型不能過於複雜，相當於限制模型擬和資料的能力。\n",
    "\n",
    "因此若沒有發現 Over-fitting 的情況，不需要一開始就加上太強的正規化。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplement:\n",
    "\n",
    "使用Elastic Net\n",
    "\n",
    "涵蓋Ridge和Lasso兩個模型的就是Elastic Net模型，該模型綜合了兩個懲罰限制式。\n",
    "\n",
    "雖然Lasso模型會執行變數挑選，但一個源自於懲罰參數的結果就是，通常當兩個高度相關的變數的係數在被逼近成為0的過程中，可能一個會完全變成0但另為一個仍保留在模型中。此外，這種一個在內、一個在外的處理方法不是很有系統。相對的，Ridge模型的懲罰參數就稍具效率一點，可以有系統的\n",
    "將高相關性變數的係數一起降低。於是，Elastic Net模型的優勢就在於，它綜合了Ridge Penalty達到有效正規化優勢以及Lasso Penalty能夠進行變數挑選優勢。\n",
    "\n",
    "https://www.jamleecute.com/regularized-regression-ridge-lasso-elastic/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跟Ridge和Lasso一樣，並調整介於0~1之間的alpha參數。\n",
    "\n",
    "當alpha = 0.5時，Ridge和Lasso的組合是平均的，而當alpha→0時，會有較多的Ridge Penalty權重，而當alpha→1時，則會有較多的Lasso Penalty權重。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 25.42\n",
      "Using alpha:0.00\n",
      "============================\n",
      "Mean squared error: 26.45\n",
      "Using alpha:0.10\n",
      "============================\n",
      "Mean squared error: 26.60\n",
      "Using alpha:0.20\n",
      "============================\n",
      "Mean squared error: 26.65\n",
      "Using alpha:0.30\n",
      "============================\n",
      "Mean squared error: 26.76\n",
      "Using alpha:0.40\n",
      "============================\n",
      "Mean squared error: 26.94\n",
      "Using alpha:0.50\n",
      "============================\n",
      "Mean squared error: 27.22\n",
      "Using alpha:0.60\n",
      "============================\n",
      "Mean squared error: 27.59\n",
      "Using alpha:0.70\n",
      "============================\n",
      "Mean squared error: 27.98\n",
      "Using alpha:0.80\n",
      "============================\n",
      "Mean squared error: 28.43\n",
      "Using alpha:0.90\n",
      "============================\n",
      "Mean squared error: 28.95\n",
      "Using alpha:1.00\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4281.822264289709, tolerance: 3.3131348787128707\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "#建立一個Tuning Grid來做tuning:\n",
    "\n",
    "# 讀取資料集\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=4)\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "seq = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "ElasticNet_mse = []\n",
    "\n",
    "for alpha in seq:\n",
    "    lasso_test = linear_model.Lasso(alpha=alpha)\n",
    "    lasso_test.fit(x_train, y_train)\n",
    "    y_pred6 = lasso_test.predict(x_test)\n",
    "    ElasticNet_mse.append(mean_squared_error(y_test, y_pred6))\n",
    " \n",
    "    print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred6))\n",
    "    \n",
    "    print(\"Using alpha:%.2f\"\n",
    "      %alpha)\n",
    "    print(\"============================\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 綜合比較:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>ElasticNet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.419587</td>\n",
       "      <td>25.419587</td>\n",
       "      <td>25.419587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25.455212</td>\n",
       "      <td>26.452889</td>\n",
       "      <td>26.452889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25.491958</td>\n",
       "      <td>26.603395</td>\n",
       "      <td>26.603395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25.528482</td>\n",
       "      <td>26.645595</td>\n",
       "      <td>26.645595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>25.564014</td>\n",
       "      <td>26.759413</td>\n",
       "      <td>26.759413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25.598134</td>\n",
       "      <td>26.944839</td>\n",
       "      <td>26.944839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>25.630629</td>\n",
       "      <td>27.217349</td>\n",
       "      <td>27.217349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>25.661416</td>\n",
       "      <td>27.589858</td>\n",
       "      <td>27.589858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25.690490</td>\n",
       "      <td>27.977013</td>\n",
       "      <td>27.977013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>25.717890</td>\n",
       "      <td>28.430480</td>\n",
       "      <td>28.430480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.743684</td>\n",
       "      <td>28.950512</td>\n",
       "      <td>28.950512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha      Ridge      Lasso  ElasticNet\n",
       "0     0.0  25.419587  25.419587   25.419587\n",
       "1     0.1  25.455212  26.452889   26.452889\n",
       "2     0.2  25.491958  26.603395   26.603395\n",
       "3     0.3  25.528482  26.645595   26.645595\n",
       "4     0.4  25.564014  26.759413   26.759413\n",
       "5     0.5  25.598134  26.944839   26.944839\n",
       "6     0.6  25.630629  27.217349   27.217349\n",
       "7     0.7  25.661416  27.589858   27.589858\n",
       "8     0.8  25.690490  27.977013   27.977013\n",
       "9     0.9  25.717890  28.430480   28.430480\n",
       "10    1.0  25.743684  28.950512   28.950512"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "df_comparison = DataFrame(seq, columns = [\"alpha\"])\n",
    "df_comparison[\"Ridge\"] = ridge_mse\n",
    "df_comparison[\"Lasso\"] = lasso_mse\n",
    "df_comparison[\"ElasticNet\"] = ElasticNet_mse\n",
    "\n",
    "df_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
