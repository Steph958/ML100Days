{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Day086_CB_ModelCheckPoint_HW3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPAAibD8l7ly"
      },
      "source": [
        "## Work\n",
        "1. 試比較 save_best_only 與否的差異\n",
        "2. 請僅存入將 save_weights_only 設定為 True, 並嘗試 reset ipynb 並將模型與權重重新建回並預測 x_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02W59m1Pl7l3"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "\n",
        "# Disable GPU\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrqNZtrFl7l8",
        "outputId": "09990645-d355-4c0b-9d78-e689f570932b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train, test = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbl8zSLVl7l_"
      },
      "source": [
        "## 資料前處理\n",
        "def preproc_x(x, flatten=True):\n",
        "    x = x / 255.\n",
        "    if flatten:\n",
        "        x = x.reshape((len(x), -1))\n",
        "    return x\n",
        "\n",
        "def preproc_y(y, num_classes=10):\n",
        "    if y.shape[-1] == 1:\n",
        "        y = keras.utils.to_categorical(y, num_classes)\n",
        "    return y    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHnEi6vul7mB"
      },
      "source": [
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "\n",
        "# Preproc the inputs\n",
        "x_train = preproc_x(x_train)\n",
        "x_test = preproc_x(x_test)\n",
        "\n",
        "# Preprc the outputs\n",
        "y_train = preproc_y(y_train)\n",
        "y_test = preproc_y(y_test)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmIJlqFnl7mE"
      },
      "source": [
        "from keras.layers import BatchNormalization\n",
        "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
        "    \n",
        "    input_layer = keras.layers.Input(input_shape)\n",
        "    \n",
        "    for i, n_units in enumerate(num_neurons):\n",
        "        if i == 0:\n",
        "            x = keras.layers.Dense(units=n_units, \n",
        "                                   activation=\"relu\", \n",
        "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
        "            x = BatchNormalization()(x)\n",
        "        else:\n",
        "            x = keras.layers.Dense(units=n_units, \n",
        "                                   activation=\"relu\", \n",
        "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
        "            x = BatchNormalization()(x)\n",
        "    \n",
        "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
        "    \n",
        "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MPPEHcgmZ_H",
        "outputId": "5963930d-e00d-4724-ffc9-79d9b3fc6a4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = build_mlp(input_shape=x_train.shape[1:])\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 3072)]            0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,742,474\n",
            "Trainable params: 1,740,682\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scjiAC4pl7mG"
      },
      "source": [
        "## 超參數設定\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 1024\n",
        "MOMENTUM = 0.95"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne0IeU2pl7mJ"
      },
      "source": [
        "# 載入 Callbacks\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model_ckpt = ModelCheckpoint(filepath=\"./tmp.h5\", \n",
        "                             monitor=\"val_loss\", \n",
        "                             save_best_only=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Qf69bdlcl7mL",
        "outputId": "039010a0-700e-4812-dd04-d18672e4f2bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = build_mlp(input_shape=x_train.shape[1:])\n",
        "model.summary()\n",
        "\n",
        "optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
        "\n",
        "model.fit(x_train, y_train, \n",
        "          epochs=EPOCHS, \n",
        "          batch_size=BATCH_SIZE, \n",
        "          validation_data=(x_test, y_test), \n",
        "          shuffle=True,\n",
        "          callbacks=[model_ckpt]\n",
        "         )\n",
        "\n",
        "#儲存模型以及權重\n",
        "model.save(\"final_model.h5\")\n",
        "model.save_weights(\"model_weights.h5\")\n",
        "\n",
        "# Collect results into dictionary\n",
        "train_loss = model.history.history[\"loss\"]\n",
        "valid_loss = model.history.history[\"val_loss\"]\n",
        "train_acc = model.history.history[\"accuracy\"]\n",
        "valid_acc = model.history.history[\"val_accuracy\"]\n",
        "\n",
        "#逕行預測\n",
        "pred_final = model.predict(x_test)\n",
        "\n",
        "# Load back\n",
        "model = keras.models.load_model(\"./tmp.h5\")\n",
        "# 用儲存的模型和權重預測\n",
        "pred_loadback = model.predict(x_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 3072)]            0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,742,474\n",
            "Trainable params: 1,740,682\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "49/49 [==============================] - 8s 163ms/step - loss: 2.2469 - accuracy: 0.2684 - val_loss: 2.1569 - val_accuracy: 0.1737\n",
            "Epoch 2/50\n",
            "49/49 [==============================] - 8s 158ms/step - loss: 1.7450 - accuracy: 0.3939 - val_loss: 1.9692 - val_accuracy: 0.2874\n",
            "Epoch 3/50\n",
            "49/49 [==============================] - 8s 158ms/step - loss: 1.6147 - accuracy: 0.4357 - val_loss: 1.8071 - val_accuracy: 0.3705\n",
            "Epoch 4/50\n",
            "49/49 [==============================] - 8s 158ms/step - loss: 1.5371 - accuracy: 0.4624 - val_loss: 1.7132 - val_accuracy: 0.4058\n",
            "Epoch 5/50\n",
            "49/49 [==============================] - 8s 158ms/step - loss: 1.4818 - accuracy: 0.4819 - val_loss: 1.6392 - val_accuracy: 0.4249\n",
            "Epoch 6/50\n",
            "49/49 [==============================] - 8s 159ms/step - loss: 1.4334 - accuracy: 0.4979 - val_loss: 1.5757 - val_accuracy: 0.4461\n",
            "Epoch 7/50\n",
            "49/49 [==============================] - 8s 159ms/step - loss: 1.3924 - accuracy: 0.5121 - val_loss: 1.5367 - val_accuracy: 0.4588\n",
            "Epoch 8/50\n",
            "49/49 [==============================] - 8s 160ms/step - loss: 1.3577 - accuracy: 0.5271 - val_loss: 1.5174 - val_accuracy: 0.4654\n",
            "Epoch 9/50\n",
            "49/49 [==============================] - 8s 161ms/step - loss: 1.3247 - accuracy: 0.5395 - val_loss: 1.5094 - val_accuracy: 0.4637\n",
            "Epoch 10/50\n",
            "49/49 [==============================] - 8s 159ms/step - loss: 1.2935 - accuracy: 0.5522 - val_loss: 1.4930 - val_accuracy: 0.4747\n",
            "Epoch 11/50\n",
            "49/49 [==============================] - 8s 159ms/step - loss: 1.2651 - accuracy: 0.5607 - val_loss: 1.4834 - val_accuracy: 0.4773\n",
            "Epoch 12/50\n",
            "49/49 [==============================] - 8s 160ms/step - loss: 1.2374 - accuracy: 0.5725 - val_loss: 1.4748 - val_accuracy: 0.4789\n",
            "Epoch 13/50\n",
            "49/49 [==============================] - 8s 160ms/step - loss: 1.2121 - accuracy: 0.5813 - val_loss: 1.4631 - val_accuracy: 0.4887\n",
            "Epoch 14/50\n",
            "49/49 [==============================] - 8s 158ms/step - loss: 1.1883 - accuracy: 0.5892 - val_loss: 1.4671 - val_accuracy: 0.4893\n",
            "Epoch 15/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 1.1637 - accuracy: 0.5994 - val_loss: 1.4638 - val_accuracy: 0.4882\n",
            "Epoch 16/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 1.1389 - accuracy: 0.6087 - val_loss: 1.4669 - val_accuracy: 0.4834\n",
            "Epoch 17/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 1.1160 - accuracy: 0.6183 - val_loss: 1.4594 - val_accuracy: 0.4932\n",
            "Epoch 18/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 1.0918 - accuracy: 0.6267 - val_loss: 1.4629 - val_accuracy: 0.4908\n",
            "Epoch 19/50\n",
            "49/49 [==============================] - 8s 156ms/step - loss: 1.0712 - accuracy: 0.6352 - val_loss: 1.4603 - val_accuracy: 0.4869\n",
            "Epoch 20/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 1.0498 - accuracy: 0.6426 - val_loss: 1.4769 - val_accuracy: 0.4923\n",
            "Epoch 21/50\n",
            "49/49 [==============================] - 8s 158ms/step - loss: 1.0282 - accuracy: 0.6510 - val_loss: 1.4556 - val_accuracy: 0.4926\n",
            "Epoch 22/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 1.0063 - accuracy: 0.6599 - val_loss: 1.4572 - val_accuracy: 0.4959\n",
            "Epoch 23/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 0.9843 - accuracy: 0.6696 - val_loss: 1.4545 - val_accuracy: 0.4998\n",
            "Epoch 24/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 0.9632 - accuracy: 0.6777 - val_loss: 1.4590 - val_accuracy: 0.4994\n",
            "Epoch 25/50\n",
            "49/49 [==============================] - 8s 158ms/step - loss: 0.9419 - accuracy: 0.6852 - val_loss: 1.4660 - val_accuracy: 0.4980\n",
            "Epoch 26/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 0.9213 - accuracy: 0.6949 - val_loss: 1.4684 - val_accuracy: 0.4985\n",
            "Epoch 27/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 0.9027 - accuracy: 0.7019 - val_loss: 1.4726 - val_accuracy: 0.4930\n",
            "Epoch 28/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 0.8820 - accuracy: 0.7074 - val_loss: 1.4848 - val_accuracy: 0.4977\n",
            "Epoch 29/50\n",
            "49/49 [==============================] - 8s 159ms/step - loss: 0.8609 - accuracy: 0.7183 - val_loss: 1.4983 - val_accuracy: 0.4983\n",
            "Epoch 30/50\n",
            "49/49 [==============================] - 8s 158ms/step - loss: 0.8404 - accuracy: 0.7243 - val_loss: 1.4873 - val_accuracy: 0.4978\n",
            "Epoch 31/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 0.8203 - accuracy: 0.7326 - val_loss: 1.4977 - val_accuracy: 0.4945\n",
            "Epoch 32/50\n",
            "49/49 [==============================] - 8s 156ms/step - loss: 0.8001 - accuracy: 0.7412 - val_loss: 1.4837 - val_accuracy: 0.4956\n",
            "Epoch 33/50\n",
            "49/49 [==============================] - 8s 156ms/step - loss: 0.7798 - accuracy: 0.7485 - val_loss: 1.5004 - val_accuracy: 0.4986\n",
            "Epoch 34/50\n",
            "49/49 [==============================] - 8s 156ms/step - loss: 0.7621 - accuracy: 0.7548 - val_loss: 1.5205 - val_accuracy: 0.4926\n",
            "Epoch 35/50\n",
            "49/49 [==============================] - 8s 156ms/step - loss: 0.7439 - accuracy: 0.7622 - val_loss: 1.5494 - val_accuracy: 0.4912\n",
            "Epoch 36/50\n",
            "49/49 [==============================] - 8s 156ms/step - loss: 0.7213 - accuracy: 0.7728 - val_loss: 1.5495 - val_accuracy: 0.4932\n",
            "Epoch 37/50\n",
            "49/49 [==============================] - 8s 156ms/step - loss: 0.7040 - accuracy: 0.7786 - val_loss: 1.5587 - val_accuracy: 0.4883\n",
            "Epoch 38/50\n",
            "49/49 [==============================] - 8s 156ms/step - loss: 0.6854 - accuracy: 0.7861 - val_loss: 1.5440 - val_accuracy: 0.4954\n",
            "Epoch 39/50\n",
            "49/49 [==============================] - 8s 156ms/step - loss: 0.6653 - accuracy: 0.7945 - val_loss: 1.5613 - val_accuracy: 0.4938\n",
            "Epoch 40/50\n",
            "49/49 [==============================] - 8s 156ms/step - loss: 0.6471 - accuracy: 0.8005 - val_loss: 1.5637 - val_accuracy: 0.4957\n",
            "Epoch 41/50\n",
            "49/49 [==============================] - 8s 156ms/step - loss: 0.6272 - accuracy: 0.8097 - val_loss: 1.5813 - val_accuracy: 0.4950\n",
            "Epoch 42/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 0.6087 - accuracy: 0.8160 - val_loss: 1.5822 - val_accuracy: 0.4917\n",
            "Epoch 43/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 0.5921 - accuracy: 0.8227 - val_loss: 1.6054 - val_accuracy: 0.4999\n",
            "Epoch 44/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 0.5742 - accuracy: 0.8300 - val_loss: 1.6396 - val_accuracy: 0.4949\n",
            "Epoch 45/50\n",
            "49/49 [==============================] - 8s 158ms/step - loss: 0.5582 - accuracy: 0.8365 - val_loss: 1.6256 - val_accuracy: 0.4955\n",
            "Epoch 46/50\n",
            "49/49 [==============================] - 8s 156ms/step - loss: 0.5392 - accuracy: 0.8441 - val_loss: 1.6356 - val_accuracy: 0.4910\n",
            "Epoch 47/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 0.5228 - accuracy: 0.8502 - val_loss: 1.6602 - val_accuracy: 0.4925\n",
            "Epoch 48/50\n",
            "49/49 [==============================] - 8s 158ms/step - loss: 0.5053 - accuracy: 0.8576 - val_loss: 1.6549 - val_accuracy: 0.4943\n",
            "Epoch 49/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 0.4872 - accuracy: 0.8661 - val_loss: 1.6873 - val_accuracy: 0.4875\n",
            "Epoch 50/50\n",
            "49/49 [==============================] - 8s 157ms/step - loss: 0.4731 - accuracy: 0.8717 - val_loss: 1.7015 - val_accuracy: 0.4850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8adm6KBl7mP",
        "outputId": "ea89f61f-d37a-4542-ef6d-5e099e681c07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "final_model_acc = accuracy_score(y_true=y_test.argmax(axis=-1), y_pred=pred_final.argmax(axis=-1))\n",
        "loadback_acc = accuracy_score(y_true=y_test.argmax(axis=-1), y_pred=pred_loadback.argmax(axis=-1))\n",
        "\n",
        "print(\"Accuracy of final weights: %.3f\" % final_model_acc)\n",
        "print(\"Accuracy of best weights: %.3f\" % loadback_acc)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of final weights: 0.485\n",
            "Accuracy of best weights: 0.500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etbWunbZl7mR",
        "outputId": "879b777f-339f-451c-ce22-b74b67904d11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "new_model = build_mlp(input_shape=x_train.shape[1:])\n",
        "new_model_pred = new_model.predict(x_test)\n",
        "new_model_acc = accuracy_score(y_true=y_test.argmax(axis=-1), y_pred=new_model_pred.argmax(axis=-1))\n",
        "print(\"Accuracy of best weights: %.3f\" % new_model_acc)\n",
        "\n",
        "new_model.load_weights(\"./model_weights.h5\")\n",
        "new_model_pred = new_model.predict(x_test)\n",
        "new_model_loadback_acc = accuracy_score(y_true=y_test.argmax(axis=-1), y_pred=new_model_pred.argmax(axis=-1))\n",
        "print(\"Accuracy of best weights: %.3f\" % new_model_loadback_acc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of best weights: 0.115\n",
            "Accuracy of best weights: 0.485\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}